{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c9d3d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d941d500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'user_class_min_1', 'user_feat_1', 'user_prob_1', 'user_resp_1', 'user_source_1', 'user_tr_order_1', 'user_train_prob_1', 'user_weights_1'])\n"
     ]
    }
   ],
   "source": [
    "#Load in the MATLAB file with all the data\n",
    "data = scipy.io.loadmat('data_CRM_SN_vs_MN_imbalLDA_order_proj_1.mat')\n",
    "\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2d15a9f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(432, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"user_resp_1\"][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cc160e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Had to index them like this because there was an unnecessary dimension \n",
    "\n",
    "# user trail order\n",
    "tr_order = data['user_tr_order_1'][0]\n",
    "\n",
    "# projection scores\n",
    "proj_score = data['user_prob_1'][0]\n",
    "\n",
    "# source and response label\n",
    "source_label = data['user_source_1'][0]\n",
    "resp_label = data['user_resp_1'][0]\n",
    "\n",
    "# features, group the channels and average over the windows,\n",
    "# those are called features, and we use the features for training\n",
    "behav_feat = data['user_feat_1'][0]\n",
    "\n",
    "len(resp_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd21db58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((432, 1), (134, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_order[0].shape, tr_order[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4d9325",
   "metadata": {},
   "source": [
    "# Encodings for Each Label\n",
    "\n",
    "## *source information*\n",
    "\n",
    "1. SC (Source Correct)\n",
    "2. CR (Correct Rejection)\n",
    "3. SI (Source Incorrect)\n",
    "4. Miss \n",
    "5. FA  (False Alarm)\n",
    "\n",
    "## *label for the source response*\n",
    "\n",
    "1. RS (Remember Source)\n",
    "2. RO (Remember Other)\n",
    "3. F (Familiarity)\n",
    "4. MN (Maybe New) \n",
    "5. SN (Sure New)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46643f8",
   "metadata": {},
   "source": [
    "# Preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1d126cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data_CRM_SN_vs_MN_imbalLDA_order_proj_1.mat'\n",
    "\n",
    "# wrapper class for data preprocessing\n",
    "class preproc:\n",
    "    \n",
    "    # class attributes\n",
    "    source_info = [\"SC\", \"CR\", \"SI\", \"M\", \"FA\"]\n",
    "    response_info = [\"RS\", \"RO\", \"F\", \"MN\", \"SN\"]\n",
    "    \n",
    "    def __init__(self, file_path):\n",
    "        \n",
    "        data = scipy.io.loadmat(file_path)\n",
    "        # user trail order\n",
    "        self.tr_order = data['user_tr_order_1'][0]\n",
    "\n",
    "        # projection scores\n",
    "        self.proj_score = data['user_prob_1'][0]\n",
    "\n",
    "        # source and response label\n",
    "        self.source_label = data['user_source_1'][0]\n",
    "        self.resp_label = data['user_resp_1'][0]\n",
    "\n",
    "        # features, group the channels and average over the windows,\n",
    "        # those are called features, and we use the features for training\n",
    "        self.behav_feat = data['user_feat_1'][0]\n",
    "        \n",
    "        self.data = data\n",
    "    \n",
    "    def prepare_labels(self, pos_source_label: int, pos_resp_label: int,\n",
    "                             neg_source_label: int, neg_resp_label: int):\n",
    "        \"\"\"\n",
    "        Preaparing the positive and negative class label in a multi-class \n",
    "        classification senarios\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        pos_source_label : int\n",
    "            the positive class's source label.\n",
    "            for details, please refer to the above encodings\n",
    "        pos_resp_label : int\n",
    "            the positive class's response label\n",
    "        neg_source_label : int\n",
    "            the negative class's source label\n",
    "        neg_response_label : int\n",
    "            the negative class's response label\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        data_x : np.ndarray\n",
    "            the input for the formatted data\n",
    "        data_y : np.ndarray\n",
    "            the ground truth label\n",
    "        data_subject : np.ndarray\n",
    "            th subject number that corresponds to the data_x and data_y\n",
    "        \"\"\"\n",
    "        temp_data_x = []\n",
    "        temp_data_y = []\n",
    "        temp_data_s = []\n",
    "\n",
    "        # parse the label into human readable format\n",
    "        positive_label = self.source_info[pos_source_label-1] + self.response_info[pos_resp_label-1]\n",
    "        negative_label = self.source_info[neg_source_label-1] + self.response_info[neg_resp_label-1]\n",
    "\n",
    "        # keep track of each subject number, \n",
    "        # for later LOSO\n",
    "\n",
    "        for subject, zipped in enumerate(zip(self.source_label, self.resp_label, self.behav_feat)):\n",
    "            source, response, behavior_feature = zipped\n",
    "            # use the logical intersection to subtract out the indices \n",
    "            # of the positive and negative class\n",
    "            pos_index = (\n",
    "                (source.flatten()==pos_source_label) &\n",
    "                (response.flatten()==pos_resp_label)\n",
    "                        )\n",
    "            neg_index = (\n",
    "                (source.flatten()==neg_source_label) & \n",
    "                (response.flatten()==neg_resp_label)\n",
    "            )\n",
    "\n",
    "            temp_data_x.append(behavior_feature[pos_index,:])\n",
    "            temp_data_x.append(behavior_feature[neg_index,:])\n",
    "\n",
    "            temp_data_y.append([positive_label for x in behavior_feature[pos_index,:]])\n",
    "            temp_data_y.append([negative_label for x in behavior_feature[neg_index,:]])\n",
    "\n",
    "            temp_data_s.append([subject for x in behavior_feature[pos_index,:]])\n",
    "            temp_data_s.append([subject for x in behavior_feature[neg_index,:]])\n",
    "        # stacking the data in different dimension together\n",
    "        data_x = np.vstack(temp_data_x)\n",
    "        data_y = np.concatenate(temp_data_y)\n",
    "        data_subject = np.concatenate(temp_data_s)\n",
    "        return data_x, data_y, data_subject\n",
    "    \n",
    "    def filter_index(self, pos_source_label: int, pos_resp_label: int,\n",
    "                           neg_source_label: int, neg_resp_label: int):\n",
    "        \"\"\"\n",
    "        A simplified version of prepare label. Instead of returns all the\n",
    "        dataset (X, y, group), this only returns a boolean array of the corresponding index\n",
    "        Since the data is in a nested array (in other words, 2-d array with different dim),\n",
    "        the returned element should also be a nested array.\n",
    "        \n",
    "        The purpose of this is to prepared for multi-subclass merge for a single class preparation\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        pos_source_label : int\n",
    "            the positive class's source label.\n",
    "            for details, please refer to the above encodings\n",
    "        pos_resp_label : int\n",
    "            the positive class's response label\n",
    "        neg_source_label : int\n",
    "            the negative class's source label\n",
    "        neg_response_label : int\n",
    "            the negative class's response label\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        pos_idx : np.ndarray\n",
    "            the nested boolean array that indicates the location of\n",
    "            the positive class.\n",
    "        neg_idx : np.ndarray \n",
    "            the nested boolean array that indicates the location of\n",
    "            the negative class.\n",
    "        \"\"\"\n",
    "        pos_idx, neg_idx = [], []\n",
    "        \n",
    "        for source, response, behavior_feature in zip(\n",
    "            self.source_label, self.resp_label, self.behav_feat\n",
    "        ):\n",
    "            # use the logical intersection to subtract out the indices \n",
    "            # of the positive and negative class\n",
    "            pos_index_single_subject = (\n",
    "                (source.flatten()==pos_source_label) &\n",
    "                (response.flatten()==pos_resp_label)\n",
    "                        )\n",
    "            neg_index_single_subject = (\n",
    "                (source.flatten()==neg_source_label) & \n",
    "                (response.flatten()==neg_resp_label)\n",
    "            )\n",
    "            # aggregate back\n",
    "            pos_idx.append(pos_index_single_subject)\n",
    "            neg_idx.append(neg_index_single_subject)\n",
    "        \n",
    "        return np.array(pos_idx, dtype=object), np.array(neg_idx, dtype=object)\n",
    "    \n",
    "    def merge_two_class(self, pos1, neg1, pos2, neg2):\n",
    "        \"\"\"\n",
    "        Apply logical OR to two positive class and two negative class\n",
    "        Purpose is to merge 1 and 2\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        pos1 : np.ndarray([Object])\n",
    "            the positive class 1 index array\n",
    "        neg1 : np.ndarray([Object])\n",
    "            the negative class 1 index array\n",
    "        pos2 : np.ndarray([Object])\n",
    "            the positive class 2 index array\n",
    "        neg2 : np.ndarray([Object])\n",
    "            the negative class 2 index array\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pos_idx : np.ndarray\n",
    "            the merged nested boolean array that indicates the location of\n",
    "            the positive class.\n",
    "        neg_idx : np.ndarray \n",
    "            the merged nested boolean array that indicates the location of\n",
    "            the negative class.\n",
    "        \"\"\"\n",
    "        pos_idx, neg_idx = [], []\n",
    "        for p1, n1, p2, n2 in zip(pos1, neg1, pos2, neg2):\n",
    "            pos_idx.append((p1 | p2))\n",
    "            neg_idx.append((n1 | n2))\n",
    "        return np.array(pos_idx, dtype=object), np.array(neg_idx, dtype=object)\n",
    "    \n",
    "    def get_data_by_index(self, pos_idx, neg_idx):\n",
    "        \"\"\"\n",
    "        given positive and negative index array, indexing out the\n",
    "        given data matrices and flattern them out\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        pos_idx : np.ndarray\n",
    "            the nested boolean array that indicates the position of the\n",
    "            positive class\n",
    "        neg_idx : np.ndarray\n",
    "            the nested boolean array that indicates the position of the\n",
    "            negative class\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        X : np.ndarray\n",
    "            the input for the formatted flattern data\n",
    "        y : np.ndarray\n",
    "            the ground truth label\n",
    "        subject : np.ndarray\n",
    "            th subject number that corresponds to the data_x and data_y\n",
    "        \"\"\"\n",
    "        X, y, subject = np.array([]), np.array([]), np.array([])\n",
    "        \n",
    "        for subject_num, zipped in enumerate(zip(pos_idx, neg_idx, self.behav_feat)):\n",
    "            pos, neg, behavior_feature = zipped\n",
    "            pos_len, neg_len = len(pos), len(neg)\n",
    "            \n",
    "            # append positive class\n",
    "            try: \n",
    "                X = np.vstack([X, behavior_feature[pos, :]])\n",
    "            except ValueError:\n",
    "                # catch the first case where the X is empty\n",
    "                X = behavior_feature[pos, :]\n",
    "            y = np.append(y, np.repeat(1, pos_len))\n",
    "            \n",
    "            # append negative class\n",
    "            X = np.vstack([X, behavior_feature[neg, :]])\n",
    "            y = np.append(y, np.repeat(-1, neg_len))\n",
    "            \n",
    "            # record their subject id\n",
    "            subject = np.append(subject, np.repeat(subject_num, pos_len + neg_len))\n",
    "        return X, y, subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b67e0bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre = preproc(file_path)\n",
    "X, y, group = data_pre.prepare_labels(2,5,2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "23a8fe22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3898, 72)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preproc = preproc(file_path)\n",
    "pos1, neg1 = data_preproc.filter_index(2,5,2,4)\n",
    "pos2, neg2 = data_preproc.filter_index(4,5,4,4)\n",
    "pos_idx, neg_idx = data_preproc.merge_two_class(pos1, neg1, pos2, neg2)\n",
    "X, y, subject = data_preproc.get_data_by_index(pos_idx, neg_idx)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d37c5cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., ..., -1., -1., -1.])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0da0db92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRSN', 'CRSN', 'CRSN', ..., 'CRMN', 'CRMN', 'CRMN'], dtype='<U4')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425a94ce",
   "metadata": {},
   "source": [
    "# trainning - `CRSN` v.s. `CRMN`\n",
    "\n",
    "This has limited performance since `CRSN` and `CRMN` are only a subset of the `SN` and `MN` categories. To fully train on the `SN` and `MN` class, we need to merge `CRSN` and `MSN` and `CRMN` and `MMN` together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d825ef9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 26 groups\n"
     ]
    }
   ],
   "source": [
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "print(f\"there are {logo.get_n_splits(X, y, group)} groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "401cb3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for train_idx, test_idx in logo.split(X, y, group):\n",
    "    X_train, y_train = X[train_idx,:], y[train_idx]\n",
    "    X_test, y_test = X[test_idx,:], y[test_idx]\n",
    "    LDA = LinearDiscriminantAnalysis(shrinkage = 'auto', solver = 'eigen')\n",
    "    LDA.fit(X_train, y_train)\n",
    "    scores.append(LDA.score(X_test, y_test))\n",
    "scores = np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e574c3ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5778343140636092"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b37c65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
