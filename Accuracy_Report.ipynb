{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c9d3d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import LeaveOneGroupOut, cross_val_score, cross_val_predict\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import scipy.stats as stats\n",
    "from mat_preproc import preproc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4d9325",
   "metadata": {},
   "source": [
    "# Encodings for Each Label\n",
    "\n",
    "## *source information*\n",
    "\n",
    "1. SC (Source Correct)\n",
    "2. CR (Correct Rejection)\n",
    "3. SI (Source Incorrect)\n",
    "4. Miss \n",
    "5. FA  (False Alarm)\n",
    "\n",
    "## *label for the source response*\n",
    "\n",
    "1. RS (Remember Source)\n",
    "2. RO (Remember Other)\n",
    "3. F (Familiarity)\n",
    "4. MN (Maybe New) \n",
    "5. SN (Sure New)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cdb6a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class attributes\n",
    "source_info = [\"SC\", \"CR\", \"SI\", \"M\", \"FA\"]\n",
    "response_info = [\"RS\", \"RO\", \"F\", \"MN\", \"SN\"]\n",
    "\n",
    "# the x-axis on the projection graph\n",
    "x_axis = [(1, 1), (3, 1), (5, 1), (1, 2), (5, 2), (1, 3), (3, 3), (5, 3), (4, 4), (2, 4), (4, 5), (2, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8c3ce70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC-RS\n",
      "SI-RS\n",
      "FA-RS\n",
      "SC-RO\n",
      "FA-RO\n",
      "SC-F\n",
      "SI-F\n",
      "FA-F\n",
      "M-MN\n",
      "CR-MN\n",
      "M-SN\n",
      "CR-SN\n"
     ]
    }
   ],
   "source": [
    "for source, resp in x_axis:\n",
    "    print(f\"{source_info[source-1]}-{response_info[resp-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46643f8",
   "metadata": {},
   "source": [
    "# Preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23a8fe22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3813, 72)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiple group\n",
    "file_path = \"data_imbalLDA_1.mat\"\n",
    "\n",
    "data_preproc = preproc(file_path, experiment_num=1)\n",
    "pos1, neg1 = data_preproc.filter_index(2,5,2,4)\n",
    "pos2, neg2 = data_preproc.filter_index(4,5,4,4)\n",
    "\n",
    "pos_idx, neg_idx = data_preproc.merge_two_class(pos1, neg1, pos2, neg2)\n",
    "X, y, subject = data_preproc.get_data_by_index(pos_idx, neg_idx)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d37c5cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3813,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6927059d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3813,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72198ae1",
   "metadata": {},
   "source": [
    "# Replicate Acc based on Kueida's Method\n",
    "\n",
    "Though unable to find the exact implementations and records of how Kueida calculated the reported values, we scrupulously followed the descriptions in the literature and replicated the result as best we could. \n",
    "\n",
    "First, leave-one-subject-out cross-validation was built. Within each fold, an LDA, with auto shrinkage along with an eigen solver, was fitted on the training data. Subsequently, the model's accuracy was evaluated based on the left-out subject. Since the literature mentioned that “The accuracy of the classifiers were calculated on balanced test data,” when using an imbalanced test-set (left-out subject) to evaluate the model’s performance within the fold, we randomly drop out the observations from the outweighed class (the class that has more observation from other) and calculate the accuracy based on the balanced test set. We repetitively balanced the test-set 10 times to smooth the randomness effect. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f93ef372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc_balanced(clf, trail_num):\n",
    "    \"\"\"\n",
    "    A summary function that calculate the accuracy in the literature\n",
    "    based the aforementioned approach. \n",
    "    \n",
    "    clf and trail_num can be used to specify which classifier and which\n",
    "    experiment that we wish to learn.\n",
    "    \"\"\"\n",
    "    file_path = f\"data_imbalLDA_{trail_num}.mat\"\n",
    "    data_preproc = preproc(file_path, trail_num)\n",
    "    if clf == \"SN_MN\":\n",
    "        pos1, neg1 = data_preproc.filter_index(2,5,2,4)\n",
    "        pos2, neg2 = data_preproc.filter_index(4,5,4,4)\n",
    "    elif clf == \"F_CR\":\n",
    "        pos1, neg1 = data_preproc.filter_index(1,3,2,4)\n",
    "        pos2, neg2 = data_preproc.filter_index(3,3,2,5)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown Classifier. Should be either `SN_MN` or `F_CR`\")\n",
    "    pos_idx, neg_idx = data_preproc.merge_two_class(pos1, neg1, pos2, neg2)\n",
    "    X, y, subject = data_preproc.get_data_by_index(pos_idx, neg_idx)\n",
    "\n",
    "    logo = LeaveOneGroupOut()\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, test_idx in logo.split(X, y, subject):\n",
    "        X_train, y_train = X[train_idx,:], y[train_idx]\n",
    "        X_test, y_test = X[test_idx,:], y[test_idx]\n",
    "        LDA = LinearDiscriminantAnalysis(shrinkage = None, solver = 'eigen')\n",
    "        LDA.fit(X_train, y_train)\n",
    "        # randomly drop datapoint to balance class\n",
    "        pos_idx, neg_idx = np.arange(len(test_idx))[y_test == 1], np.arange(len(test_idx))[y_test != 1]\n",
    "        pos_len, neg_len = len(pos_idx), len(neg_idx)\n",
    "        acc = []\n",
    "        for _ in range(10):\n",
    "            if pos_len > neg_len:\n",
    "                # when there are more positive class than negative\n",
    "                # randomly drop positive class to equivalent the negative class\n",
    "                pos_chosen = np.random.choice(pos_idx, neg_len, replace=False)\n",
    "                neg_chosen = neg_idx\n",
    "            else:\n",
    "                pos_chosen = pos_idx\n",
    "                neg_chosen = np.random.choice(neg_idx, pos_len, replace=False)\n",
    "            filter_test_idx = np.concatenate([pos_chosen, neg_chosen])\n",
    "            X_test_balanced, y_test_balanced = X_test[filter_test_idx, :], y_test[filter_test_idx]\n",
    "            assert sum(y_test_balanced) == 0 # to check whether they are balanced class\n",
    "            acc.append(LDA.score(X_test_balanced, y_test_balanced))\n",
    "        acc = np.array(acc)\n",
    "        scores.append(acc)\n",
    "    scores = np.array(scores)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9fdc8b",
   "metadata": {},
   "source": [
    "## Reports of Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2458cdad",
   "metadata": {},
   "source": [
    "The reported values is in the image. The accuracy we generated is consistently lower than the reported values.\n",
    "![reported_table](img/reported_table.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f1f5ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5304756678134714, 0.515777909215031],\n",
       " [0.5559914866368215, 0.5130120075747037]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "accs = [\n",
    "    [cal_acc_balanced(\"SN_MN\", 1), cal_acc_balanced(\"F_CR\", 1)],\n",
    "    [cal_acc_balanced(\"SN_MN\", 2),  cal_acc_balanced(\"F_CR\", 2)]\n",
    "]\n",
    "accs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdcf815",
   "metadata": {},
   "source": [
    "![summary](img/sim_vs_reported.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80899e20",
   "metadata": {},
   "source": [
    "acc reported in the literature is 0.5653"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0b40ee",
   "metadata": {},
   "source": [
    "# Test the AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "306b63bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.575871522339723"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"data_imbalLDA_1.mat\"\n",
    "data_preproc = preproc(file_path, 1)\n",
    "# combine SN and MN\n",
    "pos1, neg1 = data_preproc.filter_index(2,5,2,4)\n",
    "pos2, neg2 = data_preproc.filter_index(4,5,4,4)\n",
    "\n",
    "pos_idx, neg_idx = data_preproc.merge_two_class(pos1, neg1, pos2, neg2)\n",
    "X, y, subject = data_preproc.get_data_by_index(pos_idx, neg_idx)\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "scores = []\n",
    "\n",
    "y_pred_prob = []\n",
    "y_true = []\n",
    "\n",
    "for train_idx, test_idx in logo.split(X, y, subject):\n",
    "    X_train, y_train = X[train_idx,:], y[train_idx]\n",
    "    X_test, y_test = X[test_idx,:], y[test_idx]\n",
    "    LDA = LinearDiscriminantAnalysis(shrinkage = 'auto', solver = 'eigen')\n",
    "    LDA.fit(X_train, y_train)\n",
    "    y_pred_prob.append(LDA.predict_proba(X_test)[:,1])\n",
    "    y_true.append(y_test)\n",
    "y_pred_prob, y_true = np.concatenate(y_pred_prob), np.concatenate(y_true)\n",
    "roc_auc_score(y_true, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0f5c43",
   "metadata": {},
   "source": [
    "The literature report this number as 0.5564"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c8d5b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6373880191345944"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"data_imbalLDA_2.mat\"\n",
    "\n",
    "data_preproc = preproc(file_path, 2)\n",
    "# combine SN and MN\n",
    "pos1, neg1 = data_preproc.filter_index(2,5,2,4)\n",
    "pos2, neg2 = data_preproc.filter_index(4,5,4,4)\n",
    "\n",
    "pos_idx, neg_idx = data_preproc.merge_two_class(pos1, neg1, pos2, neg2)\n",
    "X, y, subject = data_preproc.get_data_by_index(pos_idx, neg_idx)\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "scores = []\n",
    "\n",
    "y_pred_prob = []\n",
    "y_true = []\n",
    "\n",
    "for train_idx, test_idx in logo.split(X, y, subject):\n",
    "    X_train, y_train = X[train_idx,:], y[train_idx]\n",
    "    X_test, y_test = X[test_idx,:], y[test_idx]\n",
    "    LDA = LinearDiscriminantAnalysis(shrinkage = 'auto', solver = 'eigen')\n",
    "    LDA.fit(X_train, y_train)\n",
    "    y_pred_prob.append(LDA.predict_proba(X_test)[:,1])\n",
    "    y_true.append(y_test)\n",
    "y_pred_prob, y_true = np.concatenate(y_pred_prob), np.concatenate(y_true)\n",
    "roc_auc_score(y_true, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e0c61c",
   "metadata": {},
   "source": [
    "The literature report this number as 0.5997"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
