{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae8944bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'user_class_min_1', 'user_feat_1', 'user_prob_1', 'user_resp_1', 'user_source_1', 'user_tr_order_1', 'user_train_prob_1', 'user_weights_1'])\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import LeaveOneGroupOut, cross_val_score, cross_val_predict\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import scipy.stats as stats\n",
    "from mat_preproc import preproc\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import pickle as pkl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "\n",
    "#Load in the MATLAB file with all the data\n",
    "data = scipy.io.loadmat('data_CRM_SN_vs_MN_imbalLDA_order_proj_1.mat')\n",
    "\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4d9325",
   "metadata": {},
   "source": [
    "# Encodings for Each Label\n",
    "\n",
    "## *source information*\n",
    "\n",
    "1. SC (Source Correct)\n",
    "2. CR (Correct Rejection)\n",
    "3. SI (Source Incorrect)\n",
    "4. Miss \n",
    "5. FA  (False Alarm)\n",
    "\n",
    "## *label for the source response*\n",
    "\n",
    "1. RS (Remember Source)\n",
    "2. RO (Remember Other)\n",
    "3. F (Familiarity)\n",
    "4. MN (Maybe New) \n",
    "5. SN (Sure New)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccf2cc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class attributes\n",
    "source_info = [\"SC\", \"CR\", \"SI\", \"M\", \"FA\"]\n",
    "response_info = [\"RS\", \"RO\", \"F\", \"MN\", \"SN\"]\n",
    "\n",
    "# the x-axis on the projection graph\n",
    "x_axis = [(1, 1), (3, 1), (5, 1), (1, 2), (5, 2), (1, 3), (3, 3), (5, 3), (4, 4), (2, 4), (4, 5), (2, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc5c3c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc(X, y, subject):\n",
    "    \"\"\"\n",
    "    use Kueida's evaluation method to evaluate the acc of the clf \n",
    "    on a balanced dataset.\n",
    "    \"\"\"\n",
    "    logo = LeaveOneGroupOut()\n",
    "    scores = []\n",
    "    for train_idx, test_idx in logo.split(X, y, subject):\n",
    "        X_train, y_train = X[train_idx,:], y[train_idx]\n",
    "        X_test, y_test = X[test_idx,:], y[test_idx]\n",
    "        LDA = LinearDiscriminantAnalysis(shrinkage = \"auto\", solver = 'eigen')\n",
    "        LDA.fit(X_train, y_train)\n",
    "        # randomly drop datapoint to balance class\n",
    "        pos_idx, neg_idx = np.arange(len(test_idx))[y_test == 1], np.arange(len(test_idx))[y_test != 1]\n",
    "        pos_len, neg_len = len(pos_idx), len(neg_idx)\n",
    "        acc = []\n",
    "        for _ in range(10):\n",
    "            if pos_len > neg_len:\n",
    "                # when there are more positive class than negative\n",
    "                # randomly drop positive class to equivalent the negative class\n",
    "                pos_chosen = np.random.choice(pos_idx, neg_len, replace=True)\n",
    "                neg_chosen = neg_idx\n",
    "            else:\n",
    "                pos_chosen = pos_idx\n",
    "                neg_chosen = np.random.choice(neg_idx, pos_len, replace=True)\n",
    "            filter_test_idx = np.concatenate([pos_chosen, neg_chosen])\n",
    "            X_test_balanced, y_test_balanced = X_test[filter_test_idx, :], y_test[filter_test_idx]\n",
    "            assert sum(y_test_balanced) == 0 # to check whether they are balanced class\n",
    "            acc.append(LDA.score(X_test_balanced, y_test_balanced))\n",
    "        acc = np.array(acc)\n",
    "        scores.append(acc)\n",
    "    return np.array(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b1fc42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_acc_SN_vs_MN(trail_num, iter_num):\n",
    "    clf_name = \"SN_vs_MN\"\n",
    "    file_path = f\"data_CRM_SN_vs_MN_imbalLDA_order_proj_{trail_num}.mat\"\n",
    "    data_preproc = preproc(file_path, trail_num)\n",
    "    pos1, neg1 = data_preproc.filter_index(2,5,2,4)\n",
    "    pos2, neg2 = data_preproc.filter_index(4,5,4,4)\n",
    "    pos_idx, neg_idx = data_preproc.merge_two_class(pos1, neg1, pos2, neg2)\n",
    "    X, y, subject = data_preproc.get_data_by_index(pos_idx, neg_idx, \n",
    "                                                   eliminate_trails=True)\n",
    "    accs = Parallel(n_jobs=8)(delayed(cal_acc)(X, y, subject)\n",
    "                              for _ in range(int(iter_num)))\n",
    "    with open(f\"{clf_name}_empirical_accs_leftout_boot_{trail_num}.pkl\", \"wb\") as f:\n",
    "        pkl.dump(accs, f)\n",
    "\n",
    "simulate_acc_SN_vs_MN(1, 1e4)\n",
    "simulate_acc_SN_vs_MN(2, 1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82f72348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_acc_F_vs_CR(trail_num, iter_num):\n",
    "    clf_name = \"F_vs_CR\"\n",
    "    file_path = f\"data_F_vs_CR_imbalLDA_order_proj_{trail_num}.mat\"\n",
    "    data_preproc = preproc(file_path, trail_num)\n",
    "    pos1, neg1 = data_preproc.filter_index(1,3,2,4)\n",
    "    pos2, neg2 = data_preproc.filter_index(3,3,2,5)\n",
    "    pos_idx, neg_idx = data_preproc.merge_two_class(pos1, neg1, pos2, neg2)\n",
    "    X, y, subject = data_preproc.get_data_by_index(pos_idx, neg_idx, \n",
    "                                                   eliminate_trails=True)\n",
    "    accs = Parallel(n_jobs=8)(delayed(cal_acc)(X, y, subject)\n",
    "                              for _ in range(int(iter_num)))\n",
    "    with open(f\"{clf_name}_empirical_accs_leftout_boot_{trail_num}.pkl\", \"wb\") as f:\n",
    "        pkl.dump(accs, f)\n",
    "\n",
    "simulate_acc_F_vs_CR(1, 1e4)\n",
    "simulate_acc_F_vs_CR(2, 1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b376b03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
